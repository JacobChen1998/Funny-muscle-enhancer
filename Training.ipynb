{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "threaded-crawford",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Conv2DTranspose\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loved-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w,img_h = 448,448\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "powerful-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 448, 448, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 56, 56, 256)       1179904   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 56, 56, 128)       295040    \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 112, 112, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 112, 112, 64)      73792     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 224, 224, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 224, 224, 32)      18464     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 224, 224, 16)      4624      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 224, 224, 3)       435       \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 448, 448, 3)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,368,291\n",
      "Trainable params: 6,368,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs1 = Input(shape=(img_h, img_w, 3,))\n",
    "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(inputs1)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(3, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=inputs1, outputs=decoder_output)\n",
    "model.compile(optimizer='adamax',loss='mse')\n",
    "print(model.summary())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "swedish-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 301\n"
     ]
    }
   ],
   "source": [
    "before = 'before_filtering/'\n",
    "after = 'after_filtering/'\n",
    "\n",
    "before2 = 'before_filtering_rm_bg/'\n",
    "after2 = 'after_filtering_rm_bg/'\n",
    "\n",
    "befores = os.listdir(before)\n",
    "afters = os.listdir(after)\n",
    "\n",
    "before2s = os.listdir(before2)\n",
    "after2s = os.listdir(after2)\n",
    "\n",
    "print(len(befores),len(afters))\n",
    "\n",
    "X = [];Y = []\n",
    "for i in range(len(befores)):\n",
    "    x = cv2.imread(before+befores[i])\n",
    "    x = cv2.resize(x,(img_w,img_w))\n",
    "    x=x/255\n",
    "    X.append(x)\n",
    "\n",
    "    y = cv2.imread(after+befores[i])\n",
    "    y = cv2.resize(y,(img_w,img_w))\n",
    "    y=y/255\n",
    "    Y.append(y)\n",
    "    \n",
    "for i in range(len(before2s)):\n",
    "    x = cv2.imread(before2+before2s[i])\n",
    "    x = cv2.resize(x,(img_w,img_w))\n",
    "    x=x/255\n",
    "    X.append(x)\n",
    "\n",
    "    y = cv2.imread(after2+before2s[i])\n",
    "    y = cv2.resize(y,(img_w,img_w))\n",
    "    y=y/255\n",
    "    Y.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "killing-springfield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((602, 448, 448, 3), (602, 448, 448, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X, Y = shuffle(X, Y, random_state=0)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handy-garden",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a00cd125ab58>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  histogram = model.fit_generator(datagen.flow(X, Y, batch_size=2),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "301/301 [==============================] - 74s 226ms/step - loss: 0.0294\n",
      "Epoch 2/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0118\n",
      "Epoch 3/200\n",
      "301/301 [==============================] - 69s 229ms/step - loss: 0.0098\n",
      "Epoch 4/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0087\n",
      "Epoch 5/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0082\n",
      "Epoch 6/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0070\n",
      "Epoch 7/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0068\n",
      "Epoch 8/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0072\n",
      "Epoch 9/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0060\n",
      "Epoch 10/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0056\n",
      "Epoch 11/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0056\n",
      "Epoch 12/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0056\n",
      "Epoch 13/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0052\n",
      "Epoch 14/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0051\n",
      "Epoch 15/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0049\n",
      "Epoch 16/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0047\n",
      "Epoch 17/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0046\n",
      "Epoch 18/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0045\n",
      "Epoch 19/200\n",
      "301/301 [==============================] - 69s 228ms/step - loss: 0.0048\n",
      "Epoch 20/200\n",
      "301/301 [==============================] - 69s 229ms/step - loss: 0.0047\n",
      "Epoch 21/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0044\n",
      "Epoch 22/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0043\n",
      "Epoch 23/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0043\n",
      "Epoch 24/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0041\n",
      "Epoch 25/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0036\n",
      "Epoch 26/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0041\n",
      "Epoch 27/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0039\n",
      "Epoch 28/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0036\n",
      "Epoch 29/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0037\n",
      "Epoch 30/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0040\n",
      "Epoch 31/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0034\n",
      "Epoch 32/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0033\n",
      "Epoch 33/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0035\n",
      "Epoch 34/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0036\n",
      "Epoch 35/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0035\n",
      "Epoch 36/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0033\n",
      "Epoch 37/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0034\n",
      "Epoch 38/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0031\n",
      "Epoch 39/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0031\n",
      "Epoch 40/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0032\n",
      "Epoch 41/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0035\n",
      "Epoch 42/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0033\n",
      "Epoch 43/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0029\n",
      "Epoch 44/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0030\n",
      "Epoch 45/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0030\n",
      "Epoch 46/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0030\n",
      "Epoch 47/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0031\n",
      "Epoch 48/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0033\n",
      "Epoch 49/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0028\n",
      "Epoch 50/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0027\n",
      "Epoch 51/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0029\n",
      "Epoch 52/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0027\n",
      "Epoch 53/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0029\n",
      "Epoch 54/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0027\n",
      "Epoch 55/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0030\n",
      "Epoch 56/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0026\n",
      "Epoch 57/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0027\n",
      "Epoch 58/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0026\n",
      "Epoch 59/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0027\n",
      "Epoch 60/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0026\n",
      "Epoch 61/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0028\n",
      "Epoch 62/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0025\n",
      "Epoch 63/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0025\n",
      "Epoch 64/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0023\n",
      "Epoch 65/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0024\n",
      "Epoch 66/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0024\n",
      "Epoch 67/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0026\n",
      "Epoch 68/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0023\n",
      "Epoch 69/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0024\n",
      "Epoch 70/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0025\n",
      "Epoch 71/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0024\n",
      "Epoch 72/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0023\n",
      "Epoch 73/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0024\n",
      "Epoch 74/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0025\n",
      "Epoch 75/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0025\n",
      "Epoch 76/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0023\n",
      "Epoch 77/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0022\n",
      "Epoch 78/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0022\n",
      "Epoch 79/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0023\n",
      "Epoch 80/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0024\n",
      "Epoch 81/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0025\n",
      "Epoch 82/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 83/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0024\n",
      "Epoch 84/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0023\n",
      "Epoch 85/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 86/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0023\n",
      "Epoch 87/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 88/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 89/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 90/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0030\n",
      "Epoch 91/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 92/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 93/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 94/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 95/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 97/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 98/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 99/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 100/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 101/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 102/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 103/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0020\n",
      "Epoch 104/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0020\n",
      "Epoch 105/200\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.0022\n",
      "Epoch 106/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0022\n",
      "Epoch 107/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 108/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0021\n",
      "Epoch 109/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0023\n",
      "Epoch 110/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0021\n",
      "Epoch 111/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 112/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0021\n",
      "Epoch 113/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 114/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0021\n",
      "Epoch 115/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0022\n",
      "Epoch 116/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0021\n",
      "Epoch 117/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 118/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0020\n",
      "Epoch 119/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 120/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0023\n",
      "Epoch 121/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 122/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0019\n",
      "Epoch 123/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 124/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 125/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 126/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 127/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 128/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0021\n",
      "Epoch 129/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0020\n",
      "Epoch 130/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0020\n",
      "Epoch 131/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0021\n",
      "Epoch 132/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0019\n",
      "Epoch 133/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 134/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 135/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0020\n",
      "Epoch 136/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0020\n",
      "Epoch 137/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 138/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0020\n",
      "Epoch 139/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 140/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0019\n",
      "Epoch 141/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0020\n",
      "Epoch 142/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0020\n",
      "Epoch 143/200\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.0019\n",
      "Epoch 144/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 145/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0019\n",
      "Epoch 146/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 147/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 148/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 149/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 150/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 151/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 152/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 153/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 154/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 155/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 156/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 157/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 158/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 159/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 160/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 161/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 162/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 163/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 164/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 165/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 166/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 167/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 168/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 169/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 170/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 171/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0020\n",
      "Epoch 172/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 173/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 174/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 175/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 176/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 177/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 178/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 179/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 180/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 181/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 182/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 183/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 184/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 185/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0019\n",
      "Epoch 186/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0019\n",
      "Epoch 187/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0017\n",
      "Epoch 188/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0017\n",
      "Epoch 189/200\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0018\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 68s 225ms/step - loss: 0.0020\n",
      "Epoch 191/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0017\n",
      "Epoch 192/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 193/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 194/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 195/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 196/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 197/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 198/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0019\n",
      "Epoch 199/200\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.0018\n",
      "Epoch 200/200\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "\n",
    "hist = model.fit_generator(datagen.flow(X, Y, batch_size=2),\n",
    "                    steps_per_epoch=len(X) / 2, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "israeli-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_200_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "instructional-sailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlSUlEQVR4nO3deXhU133/8fd3RvsOSAgBwmIRGOzYgDHGdhw7sUnAWYidNsFZ7CRNHRK7TZo0LVnaJunzJGkWu3XrQm2Hxk7cuEntxCQhP8chXmNDEJh9FWITCElIaEG7Zs7vj7kSI2kEwyKN8P28nmcezZw5d+bM1eh+dM6991xzziEiIv4TSHQDREQkMRQAIiI+pQAQEfEpBYCIiE8pAEREfCop0Q04F/n5+a6kpCTRzRARuaRs3LjxhHOuoH/5JRUAJSUllJWVJboZIiKXFDM7FKtcQ0AiIj4VVwCY2SIz22Nm5Wa2PMbzZmYPec9vNbO5Xnmamf3JzLaY2Q4z+0bUMqPN7Hkz2+f9HHXxPpaIiJzNWQPAzILAw8BiYBZwl5nN6ldtMVDq3e4FVnjlHcA7nHNXA7OBRWa2wHtuObDWOVcKrPUei4jIMImnBzAfKHfOVTjnOoGngCX96iwBnnAR64A8MyvyHp/y6iR7Nxe1zOPe/ceB91/A5xARkXMUTwBMAI5EPa70yuKqY2ZBM9sM1ADPO+fWe3UKnXNVAN7PsbHe3MzuNbMyMyurra2No7kiIhKPeALAYpT1n0Fu0DrOuZBzbjYwEZhvZleeSwOdc4845+Y55+YVFAw4iklERM5TPAFQCRRHPZ4IHDvXOs65BuBFYJFXVG1mRQDez5p4Gy0iIhcungDYAJSa2WQzSwGWAqv71VkN3O0dDbQAaHTOVZlZgZnlAZhZOnAbsDtqmXu8+/cAz17YRxnc2l3V/OeL5UP18iIil6SzBoBzrhu4H3gO2AX8zDm3w8yWmdkyr9oaoAIoBx4FPuuVFwEvmNlWIkHyvHPu195z3wEWmtk+YKH3eEi8uKeWR1+uGKqXFxG5JMV1JrBzbg2RjXx02cqo+w64L8ZyW4E5g7xmHXDruTT2fAUDRiisC9+IiETzxZnAATO0/RcR6csXAZAUVA9ARKQ/XwRAwBQAIiL9+SIAggEIOQWAiEg0fwSAegAiIgP4IgACgciJymGFgIhIL18EQNAiAaBhIBGR03wRAD09AA0DiYic5osACPYMAakHICLSyx8BYOoBiIj0548A6N0JnOCGiIiMIL4KgG4lgIhIL18EQO9OYO0DEBHp5YsA6NkHoA6AiMhp/ggA71OqByAicpovAiBgOhNYRKQ/XwRAUCeCiYgM4K8A0BCQiEgvXwSAhoBERAbyRQAkqQcgIjKALwJAk8GJiAzkiwDQXEAiIgP5IwDUAxARGcAXARDQdNAiIgP4IgBODwEluCEiIiOILwIg0DMVhIaARER6+SIAeieD0xCQiEivuALAzBaZ2R4zKzez5TGeNzN7yHt+q5nN9cqLzewFM9tlZjvM7HNRy3zdzI6a2WbvdvvF+1h9aSewiMhASWerYGZB4GFgIVAJbDCz1c65nVHVFgOl3u06YIX3sxv4onNuk5llAxvN7PmoZR90zn3/4n2c2DQVhIjIQPH0AOYD5c65CudcJ/AUsKRfnSXAEy5iHZBnZkXOuSrn3CYA51wzsAuYcBHbH5fTl4RUAIiI9IgnACYAR6IeVzJwI37WOmZWAswB1kcV3+8NGa0ys1Gx3tzM7jWzMjMrq62tjaO5A/XMBdStABAR6RVPAFiMsv5b0jPWMbMs4Gng8865Jq94BTAVmA1UAT+I9ebOuUecc/Occ/MKCgriaO5A6gGIiAwUTwBUAsVRjycCx+KtY2bJRDb+Tzrnnump4Jyrds6FnHNh4FEiQ01DQvsAREQGiicANgClZjbZzFKApcDqfnVWA3d7RwMtABqdc1VmZsAPgV3OuQeiFzCzoqiHdwDbz/tTnEVAcwGJiAxw1qOAnHPdZnY/8BwQBFY553aY2TLv+ZXAGuB2oBxoBT7hLX4j8DFgm5lt9sq+4pxbA3zXzGYTGSo6CHz6In2mAYKaCkJEZICzBgCAt8Fe069sZdR9B9wXY7lXib1/AOfcx86ppRdAU0GIiAzkjzOBg9oJLCLSnz8CwLQTWESkP18EgCaDExEZyBcBoCuCiYgM5I8A0GRwIiID+CIAdEUwEZGBfBEAGgISERnIHwGgqSBERAbwRQD0TAWh8wBERE7zRQAkBXQmsIhIf74IgICGgEREBvBFAEBkP4CGgERETvNPAJipByAiEsU3ARAI6DBQEZFovgmAoJkCQEQkim8CIBBQAIiIRPNNAAQDpqkgRESi+CcANAQkItKHfwJAPQARkT58FQDqAYiInOabAAiYaSoIEZEovgkADQGJiPTlqwDo1hCQiEgv3wRAwDQdtIhINN8EgHYCi4j05ZsACGgyOBGRPuIKADNbZGZ7zKzczJbHeN7M7CHv+a1mNtcrLzazF8xsl5ntMLPPRS0z2syeN7N93s9RF+9jDZQU1HTQIiLRzhoAZhYEHgYWA7OAu8xsVr9qi4FS73YvsMIr7wa+6JybCSwA7otadjmw1jlXCqz1Hg8ZTQctItJXPD2A+UC5c67COdcJPAUs6VdnCfCEi1gH5JlZkXOuyjm3CcA51wzsAiZELfO4d/9x4P0X9lHOTJPBiYj0FU8ATACORD2u5PRGPO46ZlYCzAHWe0WFzrkqAO/n2Fhvbmb3mlmZmZXV1tbG0dzYgqbzAEREosUTABajrP+W9Ix1zCwLeBr4vHOuKf7mgXPuEefcPOfcvIKCgnNZtA/1AERE+oonACqB4qjHE4Fj8dYxs2QiG/8nnXPPRNWpNrMir04RUHNuTT83mg1URKSveAJgA1BqZpPNLAVYCqzuV2c1cLd3NNACoNE5V2VmBvwQ2OWceyDGMvd49+8Bnj3vTxEHnQcgItJX0tkqOOe6zex+4DkgCKxyzu0ws2Xe8yuBNcDtQDnQCnzCW/xG4GPANjPb7JV9xTm3BvgO8DMz+wvgMPDnF+1TxRAIGCFt/0VEep01AAC8DfaafmUro+474L4Yy71K7P0DOOfqgFvPpbEXIqipIERE+vDNmcDBQEBDQCIiUXwUAOgwUBGRKD4KAO0EFhGJ5psA0GRwIiJ9+SYAggFNBiciEs0/AWC6IpiISDTfBEBAPQARkT58EwCaDlpEpC/fBEBkMrhEt0JEZOTwTQAkBTQdtIhINN8EgM4DEBHpyzcBEDDtBBYRieabAAgG0E5gEZEovgkAXRFMRKQv3wSArgksItKXfwIgoDOBRUSi+SYAAmY4B069ABERwEcBEAxELkym/QAiIhH+CwD1AEREAB8GQFjTQYiIAH4KAFMPQEQkmm8CIKB9ACIiffgmAIKR7b+mgxAR8fgnALQTWESkD98EgIaARET68k0A9O4EVgCIiAB+CgD1AERE+ogrAMxskZntMbNyM1se43kzs4e857ea2dyo51aZWY2Zbe+3zNfN7KiZbfZut1/4xxlc73kA2gcgIgLEEQBmFgQeBhYDs4C7zGxWv2qLgVLvdi+wIuq5HwGLBnn5B51zs73bmnNs+zlRD0BEpK94egDzgXLnXIVzrhN4CljSr84S4AkXsQ7IM7MiAOfcy0D9xWz0+QiYegAiItHiCYAJwJGox5Ve2bnWieV+b8holZmNilXBzO41szIzK6utrY3jJWM73QM475cQEXlTiScALEZZ/3+j46nT3wpgKjAbqAJ+EKuSc+4R59w859y8goKCs7zk4AI6CkhEpI94AqASKI56PBE4dh51+nDOVTvnQs65MPAokaGmIaOdwCIifcUTABuAUjObbGYpwFJgdb86q4G7vaOBFgCNzrmqM71ozz4Czx3A9sHqXgxB75PqqmAiIhFJZ6vgnOs2s/uB54AgsMo5t8PMlnnPrwTWALcD5UAr8Ime5c3sp8AtQL6ZVQL/5Jz7IfBdM5tNZKjoIPDpi/exBtIQkIhIX2cNAADvEM01/cpWRt13wH2DLHvXIOUfi7+ZFy4pEOkCaAhIRCTCN2cCe9t/9QBERDy+CYCeuYA0HbSISIR/AkDTQYuI9OGbANB00CIiffkmAIKaCkJEpA//BICmghAR6cM3AaDzAERE+vJNAGg6aBGRvvwXANoHICIC+DAAdB6AiEiEfwJA+wBERPrwTQD0TgWhISAREcBHAaAhIBGRvvwTAKadwCIi0XwTAAH1AERE+vBNAGgnsIhIX/4JgGAkAHRJSBGRCN8EQEZykIBBU3t3opsiIjIi+CYAkoIB8rNSqW5sT3RTRERGBN8EAMC43DSqmhQAIiLgswAozElTD0BExOOrACjKTeO4egAiIoDPAqAwJ43Gti7aOkOJboqISML5KgDG5aQBqBcgIoLfAiDXCwDtBxAR8WcAVKsHICLiswDQEJCISK+4AsDMFpnZHjMrN7PlMZ43M3vIe36rmc2Nem6VmdWY2fZ+y4w2s+fNbJ/3c9SFf5wzy0xNIjs1SUNAIiLEEQBmFgQeBhYDs4C7zGxWv2qLgVLvdi+wIuq5HwGLYrz0cmCtc64UWOs9HnKFuWkKABER4usBzAfKnXMVzrlO4ClgSb86S4AnXMQ6IM/MigCccy8D9TFedwnwuHf/ceD959H+czYuR+cCiIhAfAEwATgS9bjSKzvXOv0VOueqALyfY2NVMrN7zazMzMpqa2vjaO6ZjctN005gERHiCwCLUdZ/TuV46pwX59wjzrl5zrl5BQUFF/x64/PSqW5qp71LJ4OJiL/FEwCVQHHU44nAsfOo0191zzCR97MmjrZcsJnjsgk72FvdPBxvJyIyYsUTABuAUjObbGYpwFJgdb86q4G7vaOBFgCNPcM7Z7AauMe7fw/w7Dm0+7zNGp8DwI5jTcPxdiIiI9ZZA8A51w3cDzwH7AJ+5pzbYWbLzGyZV20NUAGUA48Cn+1Z3sx+CrwOzDCzSjP7C++p7wALzWwfsNB7POSKR2WQnZrETgWAiPhcUjyVnHNriGzko8tWRt13wH2DLHvXIOV1wK1xt/QiCQSMmUU57DjWONxvLSIyovjqTOAes8bnsPt4sy4QLyK+5tsAaO0McbCuJdFNERFJGH8GQFFkR7D2A4iIn/kyAKYXZpOWHODFPRd+YpmIyKXKlwGQkhRg6bWTeHbzUY7Utya6OSIiCeHLAAD49M1TCJix8qX9iW6KiEhC+DYAinLT+cA1E/l5WSWtnd2Jbo6IyLDzbQAA3Dy9gM5QmH3VpxLdFBGRYefrALh8XDYAe45rXiAR8R9fB8Ck0RmkJwfZrQAQER/ydQAEAsb0wiz2VOt8ABHxH18HAMCMcdkaAhIRX1IAjMvhxKlOaps7Et0UEZFh5fsAiN4RHA47/mzFazy0dl+CWyUiMvTimg76zWyGFwC7jzfR1hWi7NBJws7x17eWJrhlIiJDy/cBkJ+VypT8TB575QAF2anA6d5AIBDrUsciIm8Ovh8CAviPD8+lqb2LbUcbmVmUQ0tniMqTbYlulojIkFIAELk+wH9+ZC7vuqKQr717JgC7juvQUBF5c/P9EFCPW2aM5ZYZY2nt7MYMdlc1864rxiW6WSIiQ0Y9gH4yUpIoGZPJbvUARORNTgEQw+XjsjU9hIi86SkAYrh8XA4H61o0TbSIvKkpAGKYMykP5+D3u2oS3RQRkSGjAIjhrdPymZyfyQ9fPYBzLtHNEREZEgqAGAIB4xM3lrDlSANPvH6Ih18o53c7jtPSoSEhEXnz0GGgg/jA3Il8/7k9/NPqHb1lV07I4ZefvZGkoHJTRC59cW3JzGyRme0xs3IzWx7jeTOzh7znt5rZ3LMta2ZfN7OjZrbZu91+cT7SxZGZmsR/f2I+j949j83/uJBv3fEWth9t4onXDyW6aSIiF8VZewBmFgQeBhYClcAGM1vtnNsZVW0xUOrdrgNWANfFseyDzrnvX7RPc5Fdc9mo3vt3zS/muR3HeeD5vZTkZ/D2GWMx01xBInLpiqcHMB8od85VOOc6gaeAJf3qLAGecBHrgDwzK4pz2UuCmfHPS64kNz2ZT/6ojI88tp72rlCimyUict7iCYAJwJGox5VeWTx1zrbs/d6Q0SozG8UIN2lMBi9+6Ra+8b4reG1/HX/3f1t1lJCIXLLiCYBY4xz9t3qD1TnTsiuAqcBsoAr4Qcw3N7vXzMrMrKy2tjaO5g6t5GCAe24o4UvvmsHqLcf4xq929gmBts4Q9z25iUdfrqArFE5gS0VEziyeo4AqgeKoxxOBY3HWSRlsWedcdU+hmT0K/DrWmzvnHgEeAZg3b96I+Xf7s7dM5WRLJ4+9eoCqxjZunj6W915dxMMv7Oc326r4zbYqfvHGUX627HqyUnWwlYiMPPH0ADYApWY22cxSgKXA6n51VgN3e0cDLQAanXNVZ1rW20fQ4w5g+wV+lmFlZnz13TP563dM4/X9dXzlF9tY+MDLPPZKBR+cN5GHPzyX3ceb+OovtmmYSERGpLP+a+qc6zaz+4HngCCwyjm3w8yWec+vBNYAtwPlQCvwiTMt6730d81sNpEhoYPApy/i5xoWZsYX3jmDv1k4nU2HT7L86W2EnOPLi2cyKjOF/bXTeeD5vUwancHnbi3V+QMiMqLYpfTf6bx581xZWVmimzGo7lCYju4wmd6QTyjs+NL/beGZTUeZOCqdlKQAN03L5wsLZ5CbkZzg1oqIX5jZRufcvP7l+pf0IkoKBno3/gDBgPHAB2fz73fN4fJx2ZSMyeTH6w6x8MGXaGjtJBR2bDx0knB4YAh3aweyiAwx7Z0cBu+9ejzvvXo8AOsq6lj6yDqe3nSUrlCY7/x2NzdMHcP3/vxqJuSlA/Da/hN8/L838NO/XNDnZDQRkYtJPYBhtmDKGGYX5/HkukM89koFUwsy2XKkgaWPvM7Jlk7au0J85ZltdHaH+XnZkbO/oIjIeVIAJMCHr5tExYkWTpzq5Nt3XsVPPnUd1Y0dfOqJMu57chMH61qZUZjNmm1VdHTrbGMRGRoKgAR471XjyUlLYv7k0cyfPJo5k0bxrTvfwtbKBtYfqGfZzVP58u2X09TezUt7Iie/tXWG+FnZET7zk4088vJ+TrZ0nvV9FB4iciY6CihB9lY3MyojhYLs1N6y9q4QqUkBzIyuUJjrvrWWGYXZfOvOt/CZn2xk9/Fm8rNSOHGqk7yMZB784Gwa2jo51tDOZ26eSiBw+sTrlS/t58Hn9/Lvd83hnVeMS8RHFJERYrCjgBQAI9iqVw/wz7/ZiXOQkRLkoaVzuHXmWHZWNfHFn23pc+H6Ly6czl/dWgrA5iMNfGDFayQHje6Q4+GPzOVdg4RAa2c3n39qM8nBAA9/ZG7MOiJyaRssAHQU0Aj2ybdOZs6kPB59pYK/vGkKcyZFjgi6Ynwuz3z2Bv7rpQqunJDLb7Ye44Hf76W1K0R+ViorX9rPuJw0fr7sej7z5Cb+9udbuGpiLkW56X1ef291M19+ZhsbD50EYFllI2+ZmDvsn1NEEkM9gDeBts4Qf/XTTfxhdw1hF7mOwTeXXMEV43M5eKKFxf/2CldOyOH6qflUN7ZzvKmdqsY29lafIi05wDfedwX//OtdLJxVyIMfmj3o+7R3hfjaL7fz/tkTeGtp/vB9wCF2sqWTTYdPcuvMwkQ3RWRIqAfwJpaeEuSxe66lvqWTmuZ2ZhRm916spiQ/k394zyy+9sttlB06SX5WKuNy0pg0OpP3z5nAXddOYlRmCruPN/Pj1w/x6ZunUNvcwT8+u4OP31DCzdML+Punt3JTaT4HTrTy9KZK1h+oY+0XbiElKfYxBBsP1ZOTlkxpYfZwrobztuKl/TzycgWvLX8H4/PSz76AyJuEegA+0djWRUZKkORB5iM6Ut/K7Q+90nvh+/TkIC2dITJTgnSHHR3dkTOTb5lRwIt7avny4sspyc9kcn4m0wqyeHFvDWnJQZraurjvf95gVEYKz//N2xiVmRLz/ZxzhF3kbOlEW/SvL7P7eDP/tnQ2S2b3v9SFyKVPPQCfy00/89xDxaMzePFvb+GRVypo6ejm7xZdzrfX7OKNww2s+Og17DnexM6qZj53ayl3PbqOb/92d++y43PTONbY3vt4ZlEO5TXNfPWX2/ib26ZTPDqDtORg7/N1pzq47382UdvcwdOfuYG8jNghEa2mqZ3mjm6mFmQNWsc5x4lTnX2OrDqb2uaO3p3p6w/UKwDEV9QDkHNWXnOK/9tYyU2l+ayvqGPDwZMsnR+57MPmIw18/tbp/HjdQb7/u71AJCC+ueRK/nSwni1HGqg40UJTWxdh57hu8hhmFmXz2v46qhrbyUpNonRsFh+6tpiS/Ew2H27gsVcr2Ft9CoAvvWsG9719Wr/2NLPpUANPbTjMpsMNfPvOt3BtyWiWP72Vj99YwnuuGj/oZ/nlG0f5/P9uZnxuGhmpSfz+CzcP0VoTSRwdBirDyjnH6xV1VDW0829r93G4vpVgwJhTnMeozBTuf/s0dlY18eVntpEUMBZMGUPx6AxaO7tZX1HP8abTPYpZRTncOXcCm4808OutVbzv6vHcc8NlNLZ1serVg7xafgKA4tHp5KWnsLe6mfysVI42tAHwyRsnc9f8YvZUN3P0ZBtXTsjlLRNzyUlL5os/28IfdlfzqZum8L3n9lD2tdvIz4qvBxEOO0LODTqsBtDY2sWOY41cXZzXZ6LA/bWneGF3DR9dcFmf3tG52HjoJLuPN/GR6y47r+XFPzQEJMPKzLhhauRIoYVXFPLMxkrecXkhk8Zk9Na5ujiPKfmZTB2b1Wej2x0K88q+E7R0djMuJ41rLhuFmREOO0rGZPLDVw+wekvkonSjMpL5yu2X847LC5mSn0ldSye3P/QKdS0d/HzZ9TyzqZL/fu0Aq/54YEAbJ+Slc+JUB7fNKmTBlNEAlB2sZ9GVkWsVtXZGzsTeWdVEW2eIYMDYU91M0IxJYzL47bbjnDjVwbSxWcwan4NhbD/ayLuvKmLZzVM53tjOx1at51BdK8lBY95lo7l28mhwjkdfOUBbV4j/t/04j9w9j9GZKbyyr5aUYIDrpoyhqrGNZzYd5aW9tZSMyeCtpQW8c1Zhb1hsq2zk7h+up6UzRFLA+NC1k874++jsDtPRHSI9Odh7XYquUJiygycpyE5h2thLY4e9XFzqAcglp76lk9f2n6AgK5UrJ+T2+c8a4HBdK61d3Vw+LgeAow1t/GFXNdMLs5k2Nosdx5p6h6JaO7u5921TeMuEPOZ883ekJQe5bWYhXeEwv99ZTVN7N8GAkZoUoLM7zLSxWXSFwlScaOGm0gJmFeWw+3gTO441EQo7LhuTwRuHG8hMCdIVcmSkBvmHd89iX80pXtpby66qJgCunzKGd19VxDd/vZOMlCDXTBrF2t01AEwtyKTiRAvORXo/xxrbaGjtIjstiVlFOaQkBXjjcAO56clMHJXOG0caWPGRuVw/dQy/2VrF4fpWGtu6aGzrwoBTHd38sbyOtq4QKcEAC68oJDlg/GF3Te/n+/gNJew53kx1UzulhVmUjs2mqb2LtbtqCIUd+dmpXDk+h4N1LXR1O/7hPbP41dZjPLPpKCVjMrhh6hiunTyaitoWUpMCjMpM4cU9NYTDkcOS87NTWH+gnlf3nWDp/En8+TUTqTzZRsmYDLpCjtVbjtIZctSd6mDjoZPcOXcCd8yZSFN7F/WnOgkGjImj0nm1/ASvlp9g3mWjuXHaGJyDh18oJzstmU/dNJnukCMYsN4j1Jxz1J7qoCArtffIuKMNbdSd6uCqiXkxv18tHd2kJAXO2LMbTM/2tOe9ehxvbOdwfSvzJ48+59e8GDQEJHIWGw7W89grFayrqCc9Ocjcy/L42IIS5kzKIy05iHOu9w+7OxQe9ApvL+yu4YU9NaQmBfjQtZOYNvb0juuuUJj2rhBZqUmYGbuqmvjWml38sfwEn71lGqMyU/jttipumDqGD1wzkcvGZBIOR4bTfrXlGPtqTtEVClM6Npu/esc0stOS+OB/vc7+2hbSkgO0d4Uxi+z0z01PxnlHWr11Wj6TRmdw5GQrq7ccw4BbZxZy6+VjWbP9OL/acowJeem9O/AP1beSHAjwtukF5KYnU3myle1HGykenUFdSye1zR0A3DZzLPUtnWw+0kD/y1pkpyYRCBiNbV0ABAymFGRRXnOKgEHYwVhvh32N93pmUJidxvGmduZPHs2mQyfp9l44IyVIa2cIM3AOUpIC5KQlceJUZF6scTlp1LV0kJ2WzEevm8TRhnb+WH6C403tXD4um9tmFnKovpXfbquiO+xYdvNUbp05lub2Lprbu2lq72bz4QZWbznK2Ow0PjB3Akcb2gkGIC05yPM7q8lICfKBayYycVQGr++v43c7jlNamMXk/CzqTnVQdugkWalJ/MeH53DVxDxOtnTyk3WH+M8X99PWFeIb77uCe24o4VhDG09tOELlyVaCZlw/dQwZKUnUNEf2g204eJI/lp9gdnEet80q5Gbv93C+FAAiI1hLR/eAnky8OrvDPLn+ELuqmviza4qZd9moPvNC9RfyNqg9h+A656hqbKcwJ623rK0zhMORkTKwTXWnOvjec3u4fuqY3qOmaprb2V3VzPTCbDq6Q1Q3dXB1cS7JgQCH6ls52drJ+Nx0CnNS+eXmo+ytPkXxqAz+sLuaju4w9799GpPzM0lJilxU6R+f3c5zO6q5Y84ErhifQ1tXiJ3HmphZlMMdcyL7g17YXcOBEy0su2UqDa1d/GTdIS4fl83OqiZe2XeCURnJ3DAtn1lFOTy7+Sj7ak4xOiOF91xVRGcozE//NHC69fTkIHfOncDOqibeONxAQXYqzkFjWyc3Ty+gvqWTTYcbAEhNCnDbzEIqTrRQ29xObnoyV0/MY/2BemqbOygenU7lyTY6usO8c1YhobBj7e4ainLTqGnuwDnH+Lx0WjtD1Peb3DEtOcCCKWPYVtlIXUsnSQFj5Uev4bZZ53eyogJARHyjprmd/MzU3iCMdd7JG4dP0tzeTXZaEtlpyeSkJZGbkUxqUqS319zRTU5a5L/ucNj1vlZNczsNrV0UZqfFvLRrfUsnDz6/l/rWTgqyUvnQtcXMLMqhszvMv/5+L7XNHRTlpfPBeZGeRDjs2FnVhHNQmJNKc0c3Y7NTyU5LJhR2bD7SwO93VfOJG0sYm512XutDASAi4lO6JrCIiPShABAR8SkFgIiITykARER8SgEgIuJTCgAREZ9SAIiI+JQCQETEpy6pE8HMrBY4dJ6L5wMnLmJzLpaR2i4YuW1Tu87NSG0XjNy2vdnadZlzrqB/4SUVABfCzMpinQmXaCO1XTBy26Z2nZuR2i4YuW3zS7s0BCQi4lMKABERn/JTADyS6AYMYqS2C0Zu29SuczNS2wUjt22+aJdv9gGIiEhffuoBiIhIFAWAiIhP+SIAzGyRme0xs3IzW57AdhSb2QtmtsvMdpjZ57zyr5vZUTPb7N1uT0DbDprZNu/9y7yy0Wb2vJnt836OGuY2zYhaJ5vNrMnMPp+o9WVmq8ysxsy2R5UNuo7M7Mved26Pmb1rmNv1PTPbbWZbzewXZpbnlZeYWVvUuls5zO0a9HeX4PX1v1FtOmhmm73y4Vxfg20fhu475px7U9+AILAfmAKkAFuAWQlqSxEw17ufDewFZgFfB/42wevpIJDfr+y7wHLv/nLgXxL8ezwOXJao9QW8DZgLbD/bOvJ+r1uAVGCy9x0MDmO73gkkeff/JapdJdH1ErC+Yv7uEr2++j3/A+AfE7C+Bts+DNl3zA89gPlAuXOuwjnXCTwFLElEQ5xzVc65Td79ZmAXMCERbYnTEuBx7/7jwPsT1xRuBfY75873TPAL5px7GajvVzzYOloCPOWc63DOHQDKiXwXh6VdzrnfOee6vYfrgIlD8d7n2q4zSOj66mFmBnwQ+OlQvPeZnGH7MGTfMT8EwATgSNTjSkbARtfMSoA5wHqv6H6vu75quIdaPA74nZltNLN7vbJC51wVRL6cwNgEtKvHUvr+USZ6ffUYbB2NpO/dJ4HfRj2ebGZvmNlLZnZTAtoT63c3UtbXTUC1c25fVNmwr69+24ch+475IQAsRllCj301syzgaeDzzrkmYAUwFZgNVBHpgg63G51zc4HFwH1m9rYEtCEmM0sB3gf83CsaCevrbEbE987Mvgp0A096RVXAJOfcHOALwP+YWc4wNmmw392IWF/AXfT9R2PY11eM7cOgVWOUndM680MAVALFUY8nAscS1BbMLJnIL/dJ59wzAM65audcyDkXBh5liLq+Z+KcO+b9rAF+4bWh2syKvHYXATXD3S7PYmCTc67aa2PC11eUwdZRwr93ZnYP8B7gI84bNPaGC+q8+xuJjBtPH642neF3NxLWVxJwJ/C/PWXDvb5ibR8Ywu+YHwJgA1BqZpO9/ySXAqsT0RBvfPGHwC7n3ANR5UVR1e4AtvdfdojblWlm2T33iexA3E5kPd3jVbsHeHY42xWlz39liV5f/Qy2jlYDS80s1cwmA6XAn4arUWa2CPh74H3Oudao8gIzC3r3p3jtqhjGdg32u0vo+vLcBux2zlX2FAzn+hps+8BQfseGY+92om/A7UT2qO8HvprAdryVSBdtK7DZu90O/BjY5pWvBoqGuV1TiBxNsAXY0bOOgDHAWmCf93N0AtZZBlAH5EaVJWR9EQmhKqCLyH9ff3GmdQR81fvO7QEWD3O7yomMD/d8z1Z6dT/g/Y63AJuA9w5zuwb93SVyfXnlPwKW9as7nOtrsO3DkH3HNBWEiIhP+WEISEREYlAAiIj4lAJARMSnFAAiIj6lABAR8SkFgIiITykARER86v8DMiB0KOJPJEgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histogram.history['loss'])\n",
    "plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "running-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('losses_200_epochs',hist.history['loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
