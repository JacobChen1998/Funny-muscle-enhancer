{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "threaded-crawford",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Conv2DTranspose\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "powerful-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 128)       295040    \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 56, 56, 64)        73792     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 112, 112, 32)      18464     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 112, 112, 16)      4624      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 112, 112, 3)       435       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 224, 224, 3)       0         \n",
      "=================================================================\n",
      "Total params: 6,220,707\n",
      "Trainable params: 6,220,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "img_w,img_h = 224,224\n",
    "\n",
    "inputs1 = Input(shape=(img_h, img_w, 3,))\n",
    "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(inputs1)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(3, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=inputs1, outputs=decoder_output)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
    "# summarize model\n",
    "print(model.summary())\n",
    "# plot_model(model, to_file='autoencoder_colorization_baseline.png', show_shapes=True)\n",
    "    \n",
    "model.compile(optimizer='adamax',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swedish-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 204\n"
     ]
    }
   ],
   "source": [
    "before = 'before_filtering/'\n",
    "after = 'after_filtering/'\n",
    "befores = os.listdir(before)\n",
    "afters = os.listdir(after)\n",
    "print(len(befores),len(afters))\n",
    "\n",
    "X = [];Y = []\n",
    "for i in range(len(befores)):\n",
    "    x = cv2.imread(before+befores[i])\n",
    "    x = cv2.resize(x,(224,224))\n",
    "    x=x/255\n",
    "    X.append(x)\n",
    "\n",
    "    y = cv2.imread(after+befores[i])\n",
    "    y = cv2.resize(y,(224,224))\n",
    "    y=y/255\n",
    "    Y.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organic-vancouver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204, 224, 224, 3), (204, 224, 224, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handy-garden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0956\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0439\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0371\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0304\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0271\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0237\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0210\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0194\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0178\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0164\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0159\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0151\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0143\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0143\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0139\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0131\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0129\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0124\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0125\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0118\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0113\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0111\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0113\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0114\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0109\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0102\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0102\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0105\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0104\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0099\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0098\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0097\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0095\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0097\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0092\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0092\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0097\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0092\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0090\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0093\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0102\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0090\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0086\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0084\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0086\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0087\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0084\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0083\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0081\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0081\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0081\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0082\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0084\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0081\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0080\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0077\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0077\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0079\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0079\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0081\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0075\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0072\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0074\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0075\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0077\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0075\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0070\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0069\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0069\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0071\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0076\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0069\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0067\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0068\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0071\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0068\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0068\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0069\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0067\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0071\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0066\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0064\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0067\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0065\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0064\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0071\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0078\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0071\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0067\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0062\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0064\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0063\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0062\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0063\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0062\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0065\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0065\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0072\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0062\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0062\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0063\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 31s 1s/step - loss: 0.0062\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0061\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0060\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0061\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0063\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0062\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0059\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0058\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0058\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0062\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0064\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0064\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0061\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0061\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0061\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0068\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0066\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0060\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0057\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0056\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0056\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0059\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0059\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0057\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0056\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0056\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0057\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0055\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0061\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0064\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0058\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0056\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0055\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.0055\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0054\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0059\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0061\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0058\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0055\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0053\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0053\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0052\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0052\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0054\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0055\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0060\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0072\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0057\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0054\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0053\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0052\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0052\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.0052\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.0052\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.0054\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.0052\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.0051\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.0050\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.0051\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.0051\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.0051\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.0050\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.0051\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.0055\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 39s 1s/step - loss: 0.0052\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 39s 1s/step - loss: 0.0052\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.0050\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.0050\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.0050\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.0052\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.0052\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.0051\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.0055\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.0052\n",
      "Epoch 176/200\n",
      " 5/26 [====>.........................] - ETA: 23s - loss: 0.0047"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-37330ad55b75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m h = model.fit(x=X, y=Y,\n\u001b[0m\u001b[0;32m      2\u001b[0m               \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m               epochs = 200)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = model.fit(x=X, y=Y,\n",
    "              batch_size = 8,\n",
    "              epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "israeli-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_175_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ruled-polls",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-eb2ffecf8b80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MSE loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-sailing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-confidence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
